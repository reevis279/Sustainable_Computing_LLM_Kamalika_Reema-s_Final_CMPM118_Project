Team Members:
1. Reema Vishwanath
2. Kamalika De

Goals:
We would like to make an application that can calculate the amount of water, carbon emmited and electricity, CPU usage, energy metrics an LLM model uses up while answering a query. Once we have made a program, we can make a UI to make the application easier for others to use. If we can calculate wattage we can calculate emmmited  

Technologies Used:
AWS
Ollama
Docker 

Task Distribution:
How to host an LLM Model - both
How to operate AWS - both
How to use Ollama - both

Plan of Action 11/13/25
-Finish Ollama Tutorial for Both Finish b
-Go through the Docker tutorial to run an LLM locally. 
-Become confortable with working with Virtual Environments
-Build a Docker Container and install Ollama with it
-Find a way to gather necessary data

Plan of Action 11/15/25
-Figure out how to use docker with ollama
-Use OpenAI on VS code and get the prompt working
-Find a way to gather necessary data-(prompt the LLM for that)
-Create a function that calculates how long results for a certain prompt take to generate
-Kamalika-fix my code
