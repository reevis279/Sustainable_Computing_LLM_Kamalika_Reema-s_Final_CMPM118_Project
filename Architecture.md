Team Members:
1. Reema Vishwanath
2. Kamalika De

Goals:
We would like to make an application that can calculate the amount of water, carbon emmited and electricity, CPU usage, energy metrics an LLM model uses up while answering a query. Once we have made a program, we can make a UI to make the application easier for others to use. If we can calculate wattage we can calculate emmmited  

Technologies Used:
AWS
Ollama
Docker 

Task Distribution:
How to host an LLM Model - both
How to operate AWS - both
How to use Ollama - both

Plan of Action 11/13/25
-Finish Ollama Tutorial for Both Finish b
-Go through the Docker tutorial to run an LLM locally. 
-Become confortable with working with Virtual Environments
-Build a Docker Container and install Ollama with it
-Find a way to gather necessary data

Plan of Action 11/15/25<br>
-Figure out how to use docker with ollama<br>
-Use OpenAI on VS code and get the prompt working<br>
-Find a way to gather necessary data-(prompt the LLM for that)<br>
-Create a function that calculates how long results for a certain prompt take to generate<br>
-Kamalika-fix my code<br>

Plan of Action 11/20/25
-Learn about SeaBornLibrary<br>
-Learn about Pandas<br>
-Find paper about other people who tried making graphs with Bpytop.<br>
-Figure out how to translate Bpytop data into something a program can read.<br> 
-How do we create a usable dataset from Bpytop information?<br>
